{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4be50f5-874a-4469-9ab7-2c7bd85d1759",
   "metadata": {},
   "source": [
    "###  Q1. Explain the difference between linear regression and logistic regression models. Provide an example of a scenario where logistic regression would be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cae77a-feb5-482a-81c8-ee99f5f9a0c2",
   "metadata": {},
   "source": [
    "## Linear Regression : Linear regression is used to predict the continuous dependent variable using a given set of independent variables.  Linear Regression is used for solving Regression problem.  In Linear regression, we predict the value of continuous variables.\n",
    "\n",
    "## Logistic Regression :  Logistic Regression is used to predict the categorical dependent variable using a given set of independent variables.  Logistic regression is used for solving Classification problems. In logistic Regression, we predict the values of categorical variables.\n",
    "\n",
    "## example : Predicting whether a customer will churn. A bank can use logistic regression to predict whether a customer is likely to close their account based on factors such as their spending habits, account balance, and number of transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d055596b-19c2-4be3-b1ad-0fe89febd54c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "982085bf-c1a5-4ef0-afa0-3a233eaf31ad",
   "metadata": {},
   "source": [
    "## Q3. Explain the concept of regularization in logistic regression and how it helps prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57806e92-0180-4dc3-908e-42c632ee6948",
   "metadata": {},
   "source": [
    "##  Regularization is a technique used to prevent overfitting in machine learning models. Overfitting occurs when a model learns the training data too well and is unable to generalize to new data. This can happen when the model has too many parameters or when the training data is noisy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e0113d-e6b7-431a-a341-de6d584c4529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41e302ff-9d05-4714-aa09-a0543fb4c2b3",
   "metadata": {},
   "source": [
    "## Q4. What is the ROC curve, and how is it used to evaluate the performance of the logistic regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82d8558-31f3-4cb2-a4e1-e6424afd289f",
   "metadata": {},
   "source": [
    "## The ROC curve is produced by calculating and plotting the true positive rate against the false positive rate for a single classifier at a variety of thresholds.For example, in logistic regression, the threshold would be the predicted probability of an observation belonging to the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcdc889-dffa-4bcc-a8f1-9ae2b7b8430c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbb4bfd2-fa19-44fb-9db4-5d49c0149968",
   "metadata": {},
   "source": [
    "##  Q5. What are some common techniques for feature selection in logistic regression? How do these techniques help improve the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdd4ebb-90ed-42cd-844a-cfe89c11d957",
   "metadata": {},
   "source": [
    "## there are many common techniques for feature selection in logistic regression:\n",
    "## Filter methods.\n",
    "## Wrapper methods.\n",
    "## Embedded methods.\n",
    "##  The best feature selection technique to use depends on the specific problem and the data. In general, filter methods are a good choice for small datasets, while wrapper methods and embedded methods are a good choice for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05c22bf-c9ac-4467-ac0a-7645f382f275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b40eae37-a32c-424c-a915-e1aca730be8a",
   "metadata": {},
   "source": [
    "## Q6. How can you handle imbalanced datasets in logistic regression? What are some strategies for dealing with class imbalance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffd8407-3b10-41cd-b3ab-6fe9b6612a64",
   "metadata": {},
   "source": [
    "## There are a number of strategies for dealing with imbalanced datasets :\n",
    "## Oversampling.\n",
    "## Undersampling.\n",
    "## Cost-sensitive learning.\n",
    "## Ensemble learning.\n",
    "## The best strategy for dealing with imbalanced datasets depends on the specific problem and the data. In general, oversampling is a good choice when the minority class is small and important. Undersampling is a good choice when the majority class is large and noisy. Cost-sensitive learning is a good choice when the misclassification costs are not equal. Ensemble learning is a good choice when the data is small or heterogeneous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e19d95-2aaa-4f35-8ff0-4e2df02809f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede3438e-995e-4335-aeca-3822a41da172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
